# Ollama: Instalación local

Ollama es una biblioteca de inteligencia artificial que permite interactuar con modelos de lenguaje.

## Requisitos

Antes de comenzar, asegúrate de tener los siguientes requisitos:

- Python 3.x instalado en tu sistema
- pip instalado en tu sistema
-Para ejecutar Llama 3 de manera eficiente en tu PC local, se recomiendan los siguientes requisitos mínimos:
    1. Procesador (CPU): Intel Core i7 o AMD Ryzen 9 (o superior)
    2. Memoria RAM: 64 GB o más
    3. Tarjeta gráfica (GPU): NVIDIA GeForce RTX 3080 o AMD Radeon RX 6800 XT (o superior) con al menos 12 GB de memoria de video
    4. Espacio de almacenamiento: 1 TB o más de espacio libre en el disco duro
    5. Sistema operativo: Ubuntu 20.04 o superior (recomendado) o Windows 10/11
    6. Python: Versión 3.8 o superior
    7. CUDA: Versión 11.2 o superior (para aceleración de hardware en GPU)

    Si deseas ejecutar Llama 3 con mayor rapidez y eficiencia, se recomiendan los siguientes requisitos adicionales:

    1. GPU más potente: NVIDIA GeForce RTX 3090 o AMD Radeon RX 6900 XT (o superior)
    2. Más memoria RAM: 128 GB o más
    3. Más espacio de almacenamiento: 2 TB o más

    Recuerda que estos requisitos pueden variar dependiendo de la complejidad de las tareas que desees realizar con Llama 3. Asegúrate de verificar los requisitos específicos para tu caso de uso.

## Instalación

1. Ir a https://ollama.com/download

2. descargar e instalar el .exe

3. ingresar por cmd y ejecutar ollama
    ![alt text](image.png)

4. Elegir que model instalar, por ejemplo 'ollama run llama3.1' (esto es dependiendo de la maquina)
    ![alt text](image-1.png)

5. Listo para usar despues de visualizar el icono de ollama 
   ![alt text](image-2.png)







## fuentes y material de apoyo
- https://github.com/ollama/ollama
- https://hackernoon.com/es/como-usar-ollama-practicamente-con-llms-locales-y-construir-un-chatbot
- https://www.youtube.com/watch?v=yM09dcOHAsA